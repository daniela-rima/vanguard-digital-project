# Vanguard-Digital-Experiment

Performance Analysis by Danielle Steede, Daniela Rivera and Vanessa Jimenez

## Introduction

We have been assigned to analyze an experiment cunducted by the Customer Experience team at Vanguard. Our mission, should we choose to accept it, is to decide whether the experiment was successful or not.

We were given the following information:

> An A/B test that was set into motion from 3/15/2017 to 6/20/2017 by the team.

Our clients were divided in the following groups:

> Control Group: Clients interacted with Vanguardâ€™s traditional online process.

> Test Group: Clients experienced the new, spruced-up digital interface.

Both groups navigated through an identical process sequence: an initial page, three subsequent steps, and finally, a confirmation page signaling process completion.

Our goal: to see if the new design leads to a better user experience and higher process completion rates.

## Data Collected

The following datasets were essential for our analysis:

> [Client Profiles](https://github.com/data-bootcamp-v4/lessons/blob/main/5_6_eda_inf_stats_tableau/project/files_for_project/df_final_demo.txt): Includes general demographics like age, gender, and account details of our clients.

> [Digital Footprints Part 1](https://github.com/data-bootcamp-v4/lessons/blob/main/5_6_eda_inf_stats_tableau/project/files_for_project/df_final_web_data_pt_1.txt) and [Digital Footprints Part 2](https://github.com/data-bootcamp-v4/lessons/blob/main/5_6_eda_inf_stats_tableau/project/files_for_project/df_final_web_data_pt_2.txt): Both include a detailed trace of client interactions online.

> [Experiment Roster](https://github.com/data-bootcamp-v4/lessons/blob/main/5_6_eda_inf_stats_tableau/project/files_for_project/df_final_experiment_clients.txt): Includes whether the client was a part of the control or test group (if any).

## Problem & Hypotheses

Did the new design created by the Customer Experiment team successful in increasing overall client engagement and potential revenue for Vanguard?

> Completion Rate
  > Did more clients reach the confirm step in the test group than the control group?
  > We believe more clients reached the confirm step in the new design.

> Time Spent on each Step
  > Did the new design reduce the time it takes to complete all the steps?
  > We believe the new design is more efficient in directing clients to reach the final step.

> Abandonment Rate
  > Are less people "giving up" on the process with this new design?
  > We believe clients will continue the process without "giving up" at a higher rate in the new design

> Error Rate
  > Is the new design more "user friendly" so that clients don't have to go back to previous steps due to any confusion?
  > We believe in the new design clients won't have to go back to previous steps as much as in the control

## Methodology

### Data Cleaning & Transformation

### Performance Metrics (KPIs)

### Hypothesis Testing

### Experiment Evaluation

### Tableau

## Conclusions

## Further Questions

## URLs (PPT, Trello, Tableau Page)


